

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Sequence representations &mdash; Spotlight v0.1.5 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/spotlight_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Factorization models" href="../factorization/factorization.html" />
    <link rel="prev" title="Implicit sequence models" href="implicit.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/spotlight.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                v0.1.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../interactions.html">Interactions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/datasets.html">Datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../datasets/synthetic.html">Synthetic</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/movielens.html">Movielens</a></li>
<li class="toctree-l2"><a class="reference internal" href="../datasets/goodbooks.html">Goodbooks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cross_validation.html">Cross validation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="sequence.html">Sequence models</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="implicit.html">Implicit feedback models</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Sequence representations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../factorization/factorization.html">Factorization models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../factorization/implicit.html">Implicit feedback models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../factorization/explicit.html">Explicit feedback models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../factorization/representations.html">Latent representations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../layers.html">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../losses.html">Loss functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../evaluation.html">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sampling.html">Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../serialization.html">Model Serialization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../serialization.html#saving-and-loading-the-model">Saving and loading the model</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#unreleased-unreleased">Unreleased (unreleased)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#other">Other</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-1-5-2018-05-20">v0.1.5 (2018-05-20)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id1">Other</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-1-4-2018-02-18">v0.1.4 (2018-02-18)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#fixed">Fixed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id2">Other</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-1-3-2017-12-14">v0.1.3 (2017-12-14)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#added">Added</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#changed">Changed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-1-2-2017-09-10">v0.1.2 (2017-09-10)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id3">Added</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id4">Changed</a></li>
<li class="toctree-l3"><a class="reference internal" href="../changelog.html#id5">Fixed</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Spotlight</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="sequence.html">Sequence</a> &raquo;</li>
        
      <li>Sequence representations</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/sequence/representations.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-spotlight.sequence.representations">
<span id="sequence-representations"></span><h1>Sequence representations<a class="headerlink" href="#module-spotlight.sequence.representations" title="Permalink to this headline">¶</a></h1>
<p>This module contains prototypes of various ways of representing users
as functions of the items they have interacted with in the past.</p>
<dl class="class">
<dt id="spotlight.sequence.representations.CNNNet">
<em class="property">class </em><code class="sig-prename descclassname">spotlight.sequence.representations.</code><code class="sig-name descname">CNNNet</code><span class="sig-paren">(</span><em class="sig-param">num_items</em>, <em class="sig-param">embedding_dim=32</em>, <em class="sig-param">kernel_width=3</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">num_layers=1</em>, <em class="sig-param">nonlinearity='tanh'</em>, <em class="sig-param">residual_connections=True</em>, <em class="sig-param">sparse=False</em>, <em class="sig-param">benchmark=True</em>, <em class="sig-param">item_embedding_layer=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#CNNNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.CNNNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Module representing users through stacked causal atrous convolutions (<a class="footnote-reference brackets" href="#id3" id="id1">3</a>, <a class="footnote-reference brackets" href="#id4" id="id2">4</a>).</p>
<p>To represent a sequence, it runs a 1D convolution over the input sequence,
from left to right. At each timestep, the output of the convolution is
the representation of the sequence up to that point. The convolution is causal
because future states are never part of the convolution’s receptive field;
this is achieved by left-padding the sequence.</p>
<p>In order to increase the receptive field (and the capacity to encode states
further back in the sequence), one can increase the kernel width, stack
more layers, or increase the dilation factor.
Input dimensionality is preserved from layer to layer.</p>
<p>Residual connections can be added between all layers.</p>
<p>During training, representations for all timesteps of the sequence are
computed in one go. Loss functions using the outputs will therefore
be aggregating both across the minibatch and across time in the sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_items</strong> (<em>int</em>) – Number of items to be represented.</p></li>
<li><p><strong>embedding_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – Embedding dimension of the embedding layer, and the number of filters
in each convolutional layer.</p></li>
<li><p><strong>kernel_width</strong> (<em>tuple</em><em> or </em><em>int</em><em>, </em><em>optional</em>) – The kernel width of the convolutional layers. If tuple, should contain
the kernel widths for all convolutional layers. If int, it will be
expanded into a tuple to match the number of layers.</p></li>
<li><p><strong>dilation</strong> (<em>tuple</em><em> or </em><em>int</em><em>, </em><em>optional</em>) – The dilation factor for atrous convolutions. Setting this to a number
greater than 1 inserts gaps into the convolutional layers, increasing
their receptive field without increasing the number of parameters.
If tuple, should contain the dilation factors for all convolutional
layers. If int, it will be expanded into a tuple to match the number
of layers.</p></li>
<li><p><strong>num_layers</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of stacked convolutional layers.</p></li>
<li><p><strong>nonlinearity</strong> (<em>string</em><em>, </em><em>optional</em>) – One of (‘tanh’, ‘relu’). Denotes the type of non-linearity to apply
after each convolutional layer.</p></li>
<li><p><strong>residual_connections</strong> (<em>boolean</em><em>, </em><em>optional</em>) – Whether to use residual connections between convolutional layers.</p></li>
<li><p><strong>item_embedding_layer</strong> (<em>an embedding layer</em><em>, </em><em>optional</em>) – If supplied, will be used as the item embedding layer
of the network.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id3"><span class="brackets"><a class="fn-backref" href="#id1">3</a></span></dt>
<dd><p>Oord, Aaron van den, et al. “Wavenet: A generative model for raw audio.”
arXiv preprint arXiv:1609.03499 (2016).</p>
</dd>
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id2">4</a></span></dt>
<dd><p>Kalchbrenner, Nal, et al. “Neural machine translation in linear time.”
arXiv preprint arXiv:1610.10099 (2016).</p>
</dd>
</dl>
<dl class="method">
<dt id="spotlight.sequence.representations.CNNNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">user_representations</em>, <em class="sig-param">targets</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#CNNNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.CNNNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute predictions for target items given user representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>user_representations</strong> (<em>tensor</em>) – Result of the user_representation_method.</p></li>
<li><p><strong>targets</strong> (<em>tensor</em>) – Minibatch of item sequences of shape
(minibatch_size, sequence_length).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>predictions</strong> – Of shape (minibatch_size, sequence_length).</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="spotlight.sequence.representations.CNNNet.user_representation">
<code class="sig-name descname">user_representation</code><span class="sig-paren">(</span><em class="sig-param">item_sequences</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#CNNNet.user_representation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.CNNNet.user_representation" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute user representation from a given sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The first element contains all representations from step
-1 (no items seen) to t - 1 (all but the last items seen).
The second element contains the final representation
at step t (all items seen). This final state can be used
for prediction or evaluation.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tuple (all_representations, final_representation)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="spotlight.sequence.representations.LSTMNet">
<em class="property">class </em><code class="sig-prename descclassname">spotlight.sequence.representations.</code><code class="sig-name descname">LSTMNet</code><span class="sig-paren">(</span><em class="sig-param">num_items</em>, <em class="sig-param">embedding_dim=32</em>, <em class="sig-param">item_embedding_layer=None</em>, <em class="sig-param">sparse=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#LSTMNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.LSTMNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Module representing users through running a recurrent neural network
over the sequence, using the hidden state at each timestep as the
sequence representation, a’la <a class="footnote-reference brackets" href="#id6" id="id5">2</a></p>
<p>During training, representations for all timesteps of the sequence are
computed in one go. Loss functions using the outputs will therefore
be aggregating both across the minibatch and across time in the sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_items</strong> (<em>int</em>) – Number of items to be represented.</p></li>
<li><p><strong>embedding_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – Embedding dimension of the embedding layer, and the number of hidden
units in the LSTM layer.</p></li>
<li><p><strong>item_embedding_layer</strong> (<em>an embedding layer</em><em>, </em><em>optional</em>) – If supplied, will be used as the item embedding layer
of the network.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id6"><span class="brackets"><a class="fn-backref" href="#id5">2</a></span></dt>
<dd><p>Hidasi, Balazs, et al. “Session-based recommendations with
recurrent neural networks.” arXiv preprint arXiv:1511.06939 (2015).</p>
</dd>
</dl>
<dl class="method">
<dt id="spotlight.sequence.representations.LSTMNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">user_representations</em>, <em class="sig-param">targets</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#LSTMNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.LSTMNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute predictions for target items given user representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>user_representations</strong> (<em>tensor</em>) – Result of the user_representation_method.</p></li>
<li><p><strong>targets</strong> (<em>tensor</em>) – A minibatch of item sequences of shape
(minibatch_size, sequence_length).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>predictions</strong> – of shape (minibatch_size, sequence_length)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="spotlight.sequence.representations.LSTMNet.user_representation">
<code class="sig-name descname">user_representation</code><span class="sig-paren">(</span><em class="sig-param">item_sequences</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#LSTMNet.user_representation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.LSTMNet.user_representation" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute user representation from a given sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The first element contains all representations from step
-1 (no items seen) to t - 1 (all but the last items seen).
The second element contains the final representation
at step t (all items seen). This final state can be used
for prediction or evaluation.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tuple (all_representations, final_representation)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="spotlight.sequence.representations.MixtureLSTMNet">
<em class="property">class </em><code class="sig-prename descclassname">spotlight.sequence.representations.</code><code class="sig-name descname">MixtureLSTMNet</code><span class="sig-paren">(</span><em class="sig-param">num_items</em>, <em class="sig-param">embedding_dim=32</em>, <em class="sig-param">num_mixtures=4</em>, <em class="sig-param">item_embedding_layer=None</em>, <em class="sig-param">sparse=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#MixtureLSTMNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.MixtureLSTMNet" title="Permalink to this definition">¶</a></dt>
<dd><p>A representation that models users as mixtures-of-tastes.</p>
<p>This is accomplished via an LSTM with a layer on top that
projects the last hidden state taste vectors and
taste attention vectors that match items with the taste
vectors that are best for evaluating them.</p>
<p>For a full description of the model, see <a class="footnote-reference brackets" href="#id8" id="id7">5</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_items</strong> (<em>int</em>) – Number of items to be represented.</p></li>
<li><p><strong>embedding_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – Embedding dimension of the embedding layer, and the number of hidden
units in the LSTM layer.</p></li>
<li><p><strong>num_mixtures</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of mixture components (distinct user tastes) that
the network should model.</p></li>
<li><p><strong>item_embedding_layer</strong> (<em>an embedding layer</em><em>, </em><em>optional</em>) – If supplied, will be used as the item embedding layer
of the network.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id8"><span class="brackets"><a class="fn-backref" href="#id7">5</a></span></dt>
<dd><p>Kula, Maciej. “Mixture-of-tastes Models for Representing
Users with Diverse Interests” <a class="reference external" href="https://github.com/maciejkula/mixture">https://github.com/maciejkula/mixture</a> (2017)</p>
</dd>
</dl>
<dl class="method">
<dt id="spotlight.sequence.representations.MixtureLSTMNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">user_representations</em>, <em class="sig-param">targets</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#MixtureLSTMNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.MixtureLSTMNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute predictions for target items given user representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>user_representations</strong> (<em>tensor</em>) – Result of the user_representation_method.</p></li>
<li><p><strong>targets</strong> (<em>tensor</em>) – A minibatch of item sequences of shape
(minibatch_size, sequence_length).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>predictions</strong> – of shape (minibatch_size, sequence_length)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="spotlight.sequence.representations.MixtureLSTMNet.user_representation">
<code class="sig-name descname">user_representation</code><span class="sig-paren">(</span><em class="sig-param">item_sequences</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#MixtureLSTMNet.user_representation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.MixtureLSTMNet.user_representation" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute user representation from a given sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The first element contains all representations from step
-1 (no items seen) to t - 1 (all but the last items seen).
The second element contains the final representation
at step t (all items seen). This final state can be used
for prediction or evaluation.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tuple (all_representations, final_representation)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="spotlight.sequence.representations.PoolNet">
<em class="property">class </em><code class="sig-prename descclassname">spotlight.sequence.representations.</code><code class="sig-name descname">PoolNet</code><span class="sig-paren">(</span><em class="sig-param">num_items</em>, <em class="sig-param">embedding_dim=32</em>, <em class="sig-param">item_embedding_layer=None</em>, <em class="sig-param">sparse=False</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#PoolNet"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.PoolNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Module representing users through averaging the representations of items
they have interacted with, a’la <a class="footnote-reference brackets" href="#id10" id="id9">1</a>.</p>
<p>To represent a sequence, it simply averages the representations of all
the items that occur in the sequence up to that point.</p>
<p>During training, representations for all timesteps of the sequence are
computed in one go. Loss functions using the outputs will therefore
be aggregating both across the minibatch and across time in the sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_items</strong> (<em>int</em>) – Number of items to be represented.</p></li>
<li><p><strong>embedding_dim</strong> (<em>int</em><em>, </em><em>optional</em>) – Embedding dimension of the embedding layer.</p></li>
<li><p><strong>item_embedding_layer</strong> (<em>an embedding layer</em><em>, </em><em>optional</em>) – If supplied, will be used as the item embedding layer
of the network.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id10"><span class="brackets"><a class="fn-backref" href="#id9">1</a></span></dt>
<dd><p>Covington, Paul, Jay Adams, and Emre Sargin. “Deep neural networks for
youtube recommendations.” Proceedings of the 10th ACM Conference
on Recommender Systems. ACM, 2016.</p>
</dd>
</dl>
<dl class="method">
<dt id="spotlight.sequence.representations.PoolNet.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">user_representations</em>, <em class="sig-param">targets</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#PoolNet.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.PoolNet.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute predictions for target items given user representations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>user_representations</strong> (<em>tensor</em>) – Result of the user_representation_method.</p></li>
<li><p><strong>targets</strong> (<em>tensor</em>) – Minibatch of item sequences of shape
(minibatch_size, sequence_length).</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><strong>predictions</strong> – of shape (minibatch_size, sequence_length)</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>tensor</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="spotlight.sequence.representations.PoolNet.user_representation">
<code class="sig-name descname">user_representation</code><span class="sig-paren">(</span><em class="sig-param">item_sequences</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/spotlight/sequence/representations.html#PoolNet.user_representation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.sequence.representations.PoolNet.user_representation" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute user representation from a given sequence.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The first element contains all representations from step
-1 (no items seen) to t - 1 (all but the last items seen).
The second element contains the final representation
at step t (all items seen). This final state can be used
for prediction or evaluation.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>tuple (all_representations, final_representation)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../factorization/factorization.html" class="btn btn-neutral float-right" title="Factorization models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="implicit.html" class="btn btn-neutral float-left" title="Implicit sequence models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Maciej Kula

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>