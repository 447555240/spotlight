

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Layers &mdash; Spotlight v0.1.5 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/spotlight_theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Loss functions" href="losses.html" />
    <link rel="prev" title="Latent representations" href="factorization/representations.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html">
          

          
            
            <img src="_static/spotlight.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                v0.1.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="interactions.html">Interactions</a></li>
<li class="toctree-l1"><a class="reference internal" href="datasets/datasets.html">Datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="datasets/synthetic.html">Synthetic</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets/movielens.html">Movielens</a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets/goodbooks.html">Goodbooks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cross_validation.html">Cross validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="sequence/sequence.html">Sequence models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="sequence/implicit.html">Implicit feedback models</a></li>
<li class="toctree-l2"><a class="reference internal" href="sequence/representations.html">Sequence representations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="factorization/factorization.html">Factorization models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="factorization/implicit.html">Implicit feedback models</a></li>
<li class="toctree-l2"><a class="reference internal" href="factorization/explicit.html">Explicit feedback models</a></li>
<li class="toctree-l2"><a class="reference internal" href="factorization/representations.html">Latent representations</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Layers</a></li>
<li class="toctree-l1"><a class="reference internal" href="losses.html">Loss functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="evaluation.html">Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="sampling.html">Sampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="serialization.html">Model Serialization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="serialization.html#saving-and-loading-the-model">Saving and loading the model</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="changelog.html">Changelog</a><ul>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#unreleased-unreleased">Unreleased (unreleased)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#other">Other</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#v0-1-5-2018-05-20">v0.1.5 (2018-05-20)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id1">Other</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#v0-1-4-2018-02-18">v0.1.4 (2018-02-18)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#fixed">Fixed</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id2">Other</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#v0-1-3-2017-12-14">v0.1.3 (2017-12-14)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#added">Added</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#changed">Changed</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="changelog.html#v0-1-2-2017-09-10">v0.1.2 (2017-09-10)</a><ul>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id3">Added</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id4">Changed</a></li>
<li class="toctree-l3"><a class="reference internal" href="changelog.html#id5">Fixed</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Spotlight</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Layers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/layers.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-spotlight.layers">
<span id="layers"></span><h1>Layers<a class="headerlink" href="#module-spotlight.layers" title="Permalink to this headline">¶</a></h1>
<p>Embedding layers useful for recommender models.</p>
<dl class="class">
<dt id="spotlight.layers.BloomEmbedding">
<em class="property">class </em><code class="sig-prename descclassname">spotlight.layers.</code><code class="sig-name descname">BloomEmbedding</code><span class="sig-paren">(</span><em class="sig-param">num_embeddings</em>, <em class="sig-param">embedding_dim</em>, <em class="sig-param">compression_ratio=0.2</em>, <em class="sig-param">num_hash_functions=4</em>, <em class="sig-param">bag=False</em>, <em class="sig-param">padding_idx=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/spotlight/layers.html#BloomEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.layers.BloomEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>An embedding layer that compresses the number of embedding
parameters required by using bloom filter-like hashing.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_embeddings</strong> (<em>int</em>) – Number of entities to be represented.</p></li>
<li><p><strong>embedding_dim</strong> (<em>int</em>) – Latent dimension of the embedding.</p></li>
<li><p><strong>compression_ratio</strong> (<em>float</em><em>, </em><em>optional</em>) – The underlying number of rows in the embedding layer
after compression. Numbers below 1.0 will use more
and more compression, reducing the number of parameters
in the layer.</p></li>
<li><p><strong>num_hash_functions</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of hash functions used to compute the bloom filter indices.</p></li>
<li><p><strong>bag</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use the <code class="docutils literal notranslate"><span class="pre">EmbeddingBag</span></code> layer for the underlying embedding.
This should be faster in principle, but currently seems to perform
very poorly.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Large embedding layers are a performance problem for fitting models:
even though the gradients are sparse (only a handful of user and item
vectors need parameter updates in every minibatch), PyTorch updates
the entire embedding layer at every backward pass. Computation time
is then wasted on applying zero gradient steps to whole embedding matrix.</p>
<p>To alleviate this problem, we can use a smaller underlying embedding layer,
and probabilistically hash users and items into that smaller space. With
good hash functions, collisions should be rare, and we should observe
fitting speedups without a decrease in accuracy.</p>
<p>The idea follows the RecSys 2017 “Getting recommenders fit”<a class="footnote-reference brackets" href="#id2" id="id1">1</a>
paper. The authors use a bloom-filter-like approach to hashing. Their approach
uses one-hot encoded inputs followed by fully connected layers as
well as softmax layers for the output, and their hashing reduces the
size of the fully connected layers rather than embedding layers as
implemented here; mathematically, however, the two formulations are
identical.</p>
<p>The hash function used is murmurhash3, hashing the indices with a different
seed for every hash function, modulo the size of the compressed embedding layer.
The hash mapping is computed once at the start of training, and indexed
into for every minibatch.</p>
<p class="rubric">References</p>
<dl class="footnote brackets">
<dt class="label" id="id2"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Serra, Joan, and Alexandros Karatzoglou.
“Getting deep recommenders fit: Bloom embeddings
for sparse binary input/output networks.”
arXiv preprint arXiv:1706.03993 (2017).</p>
</dd>
</dl>
<dl class="method">
<dt id="spotlight.layers.BloomEmbedding.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">indices</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/spotlight/layers.html#BloomEmbedding.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.layers.BloomEmbedding.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Retrieve embeddings corresponding to indices.</p>
<p>See documentation on PyTorch <code class="docutils literal notranslate"><span class="pre">nn.Embedding</span></code> for details.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="spotlight.layers.ScaledEmbedding">
<em class="property">class </em><code class="sig-prename descclassname">spotlight.layers.</code><code class="sig-name descname">ScaledEmbedding</code><span class="sig-paren">(</span><em class="sig-param">num_embeddings</em>, <em class="sig-param">embedding_dim</em>, <em class="sig-param">padding_idx=None</em>, <em class="sig-param">max_norm=None</em>, <em class="sig-param">norm_type=2.0</em>, <em class="sig-param">scale_grad_by_freq=False</em>, <em class="sig-param">sparse=False</em>, <em class="sig-param">_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/spotlight/layers.html#ScaledEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.layers.ScaledEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Embedding layer that initialises its values
to using a normal variable scaled by the inverse
of the embedding dimension.</p>
<dl class="method">
<dt id="spotlight.layers.ScaledEmbedding.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/spotlight/layers.html#ScaledEmbedding.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.layers.ScaledEmbedding.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize parameters.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="spotlight.layers.ScaledEmbeddingBag">
<em class="property">class </em><code class="sig-prename descclassname">spotlight.layers.</code><code class="sig-name descname">ScaledEmbeddingBag</code><span class="sig-paren">(</span><em class="sig-param">num_embeddings</em>, <em class="sig-param">embedding_dim</em>, <em class="sig-param">max_norm=None</em>, <em class="sig-param">norm_type=2.0</em>, <em class="sig-param">scale_grad_by_freq=False</em>, <em class="sig-param">mode='mean'</em>, <em class="sig-param">sparse=False</em>, <em class="sig-param">_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/spotlight/layers.html#ScaledEmbeddingBag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.layers.ScaledEmbeddingBag" title="Permalink to this definition">¶</a></dt>
<dd><p>EmbeddingBag layer that initialises its values
to using a normal variable scaled by the inverse
of the embedding dimension.</p>
<dl class="method">
<dt id="spotlight.layers.ScaledEmbeddingBag.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/spotlight/layers.html#ScaledEmbeddingBag.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.layers.ScaledEmbeddingBag.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize parameters.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="spotlight.layers.ZeroEmbedding">
<em class="property">class </em><code class="sig-prename descclassname">spotlight.layers.</code><code class="sig-name descname">ZeroEmbedding</code><span class="sig-paren">(</span><em class="sig-param">num_embeddings</em>, <em class="sig-param">embedding_dim</em>, <em class="sig-param">padding_idx=None</em>, <em class="sig-param">max_norm=None</em>, <em class="sig-param">norm_type=2.0</em>, <em class="sig-param">scale_grad_by_freq=False</em>, <em class="sig-param">sparse=False</em>, <em class="sig-param">_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/spotlight/layers.html#ZeroEmbedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.layers.ZeroEmbedding" title="Permalink to this definition">¶</a></dt>
<dd><p>Embedding layer that initialises its values
to using a normal variable scaled by the inverse
of the embedding dimension.</p>
<p>Used for biases.</p>
<dl class="method">
<dt id="spotlight.layers.ZeroEmbedding.reset_parameters">
<code class="sig-name descname">reset_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/spotlight/layers.html#ZeroEmbedding.reset_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#spotlight.layers.ZeroEmbedding.reset_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize parameters.</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="losses.html" class="btn btn-neutral float-right" title="Loss functions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="factorization/representations.html" class="btn btn-neutral float-left" title="Latent representations" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, Maciej Kula

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>